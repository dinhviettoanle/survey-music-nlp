# Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval Systems: a Survey
Authors: Dinh-Viet-Toan Le, Louis Bigo, Mikaela Keller, Dorien Herremans

- [Representations](#representations)
  - [Event-based tokenization](#event-based-tokenization)
    - [Elementary tokens](#elementary-tokens)
    - [Composite tokens](#composite-tokens)
- [Models](#models)
  - [Recurrent models](#recurrent-models)
    - [RNN](#rnn)
    - [LSTM](#lstm)
    - [GRU](#gru)
  - [Attention-based models](#attention-based-models)
    - [End-to-end models](#end-to-end-models)
      - [Transformer decoder-only architecture](#transformer-decoder-only-architecture)
      - [Transformer encoder-only architecture](#transformer-encoder-only-architecture)
      - [Transformer encoder-decoder architecture](#transformer-encoder-decoder-architecture)
      - [Model combinations](#model-combinations)
    - [Pre-trained models](#pre-trained-models)
      - [Transformer encoder-only architecture](#transformer-encoder-only-architecture-1)
      - [Transformer decoder-only architecture](#transformer-decoder-only-architecture-1)
      - [Transformer encoder-decoder architecture](#transformer-encoder-decoder-architecture-1)
      - [Comparative studies](#comparative-studies)
- [Citation](#citation)


## Representations

### Event-based tokenization

#### Elementary tokens

| **Tokenization**                                                                  | **Score-based / Performance-based** | **Alphabet**                                                                                                                                                                                                                                                                                                   | **Grouping**                                                                                                                                                               | **Vocab. size** | **Data**    |
| --------------------------------------------------------------------------------- | ----------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------- | ----------- |
| [ABC notation](https://arxiv.org/abs/1604.08723)                                  | Score                               | Text alphabet                                                                                                                                                                                                                                                                                                  | [Bar patching](https://archives.ismir.net/ismir2023/paper/000017.pdf)                                                                                                      | N/A             | Monophonic  |
| [MIDI-like (2018)](http://doi.org/10.1007/s00521-018-3758-9)                      | Performance                         | <details>`<Note-ON>` (MIDI value) <br> `<Note-OFF>` (MIDI value) <br> `<Time-shift>` (absolute time) `<Velocity>` (integer)</details>                                                                                                                                                                          | [BPE](https://arxiv.org/abs/2304.08953), [BPE](10.5281/zenodo.10265420) [Unigram](https://arxiv.org/abs/2304.08953)                                                        | 388             | Piano       |
| [LakhNES (2019)](http://doi.org/10.5281/zenodo.3527901)                           | Performance                         | <details>`<Note-ON-[Trk]>` (MIDI value) <br> `<Note-OFF-[Trk]>` (MIDI value) <br> `<Time-shift>` (absolute time) </details>                                                                                                                                                                                    | -                                                                                                                                                                          | 630             | Multi-track |
| [REMI (2020)](http://doi.org/10.1145/3394171.3413671)                             | Score                               | <details>`<Pitch>` (MIDI value) <br> `<Duration>` (music time) <br> `<Velocity>` (integer) <br> `<Bar>` <br> `<Position>` (music time) <br> `<Chord>` (class)</details>                                                                                                                                        | [BPE](http://doi.org/10.18653/v1/2023.emnlp-main.123), [BPE](https://arxiv.org/abs/2304.08953), [BPE](10.5281/zenodo.10265420) [Unigram](https://arxiv.org/abs/2304.08953) | 332             | Piano       |
| [REMI+ (2022)](https://arxiv.org/abs/2201.10936)                                  | Score                               | <details>REMI alphabet + features: <br> `<Instrument>` (class) <br> `<Time-Signature>` (class) <br> `<Tempo>` (integer) <br></details>                                                                                                                                                                         | -                                                                                                                                                                          | N/A             | Multi-track |
| [Lee & al. (2022)](https://openreview.net/pdf?id=Jq3uTzLg9se) (ComMU)             | Score                               | <details>REMI alphabet + metadata: <br> `<BPM>` (integer) <br> `<Key>` (class) <br> `<Instrument>` (class) <br> `<Time-Signature>` (class) <br> `<Pitch-range>` (class) <br> `<Number-of-measures>` (number) <br> `<Min-velocity>` (integer) <br> `<Max-velocity>` (integer) <br> `<Rhythm>` (class)</details> | -                                                                                                                                                                          | 728             | Multi-track |
| [MusIAC (2022)](http://doi.org/10.1007/978-3-031-03789-4_22)                      | Score                               | <details>REMI alphabet + control info: <br> `<Tensile-train>` (class) <br> `<Cloud diameter>` (class) <br> `<Density>` (class) <br> `<Polyphony>` (class) <br> `<Occupation>` (class)</details>                                                                                                                | -                                                                                                                                                                          | 360             | Multi-track |
| [Gover & al. (2022)](https://archives.ismir.net/ismir2022/paper/000003.pdf)       | Score                               | <details>`<Pitch>` (MIDI value) <br> `<Duration>` (music time) <br> `<Position>` (music time) <br> `<Bar>` <br> `<Hand>` (class)</details>                                                                                                                                                                     | -                                                                                                                                                                          | N/A             | Piano       |
| [Wu & Yang (2023)](http://doi.org/10.1109/TASLP.2023.3270726) (MuseMorphose)      | Score                               | <details>`<Pitch-[Trk]>` (MIDI value) <br> `<Duration-[Trk]>` (music time) <br> `<Velocity-[Trk]>` (integer) <br> `<Bar>` <br> `<Position>` (music time) <br> `<Tempo>` (integer)</details>                                                                                                                    | -                                                                                                                                                                          | 3440            | Multi-track |
| [MultiTrack (2020)](https://arxiv.org/abs/2008.06048) (MMM)                       | Performance                         | <details>`<Start-piece>` <br> `<Start-track>/<End-track>` <br> `<Start-bar>/<End-bar>` <br> `<Start-fill><End-fill>` <br> `<Note-ON>` (MIDI value) <br> `<Note-OFF>` (MIDI value) <br> `<Time-shift>` (absolute time) <br> `<Instrument>` (class) <br> `<Density level>` (integer)</details>                   | -                                                                                                                                                                          | 440             | Multi-track |
| [MMR (2022)](https://archives.ismir.net/ismir2022/paper/000066.pdf) (SymphonyNet) | Score                               | <details>`<Start-score>/<End-score>` <br> `<Start-bar>/<End-bar>` <br>  `<Chord>` (class) <br> `<Change-track>` <br> `<Position>` (integer) <br> `<Pitch>` (MIDI value) <br> `<Duration>` (music time)</details>                                                                                               | [BPE](https://archives.ismir.net/ismir2022/paper/000066.pdf)                                                                                                               | N/A             | Multi-track |
| [TSD (2023)](http://doi.org/10.18653/v1/2023.emnlp-main.123)                      | Performance                         | <details>`<Pitch>` (MIDI value) <br> `<Velocity>` (integer) <br> `<Duration>` (absolute time) <br> `<Time-shift>` (absolute time) <br> `<Rest>` (absolute time) <br> `<Program>` (class)</details>                                                                                                             | [BPE](http://doi.org/10.18653/v1/2023.emnlp-main.123)                                                                                                                      | 249             | Multi-track |
| [Structured (2021)](https://arxiv.org/abs/2107.05944)                             | Performance                         | <details>`<Pitch>` (MIDI value) <br> `<Velocity>` (integer) <br> `<Duration>` (absolute time) <br> `<Time-shift>` (absolute time)</details>                                                                                                                                                                    | -                                                                                                                                                                          | 428             | Piano       |
| [Chen & al. (2020)](https://archives.ismir.net/ismir2020/paper/000349.pdf)        | Score (tabs)                        | <details>`<Pitch>` (MIDI value) <br> `<Duration>` (music time) <br> `<Velocity>` (integer) <br> `<Position>` (music time) <br> `<Bar>` (integer) <br> `<String>` (integer) <br> `<Fret>` (integer) <br> `<Technique>` (class) <br> `<Grooving>` (class)</details>                                              | -                                                                                                                                                                          | 231             | Guitar      |
| [Li & al. (2023)](http://doi.org/10.5281/zenodo.10110056)                         | Score                               | <details>`<Pitch-class>` (class) <br> `<Octave>` (integer) <br> `<Duration>` (music time) <br> `<Bar>` (integer) <br> `<Position>` (music time) <br> `<Velocity>` (integer)</details>                                                                                                                          | -                                                                                                                                                                          | N/A             | Monophonic  |
| [DadaGP (2021)](https://archives.ismir.net/ismir2021/paper/000076.pdf)            | Score (tabs)                        | <details>`<Start><End>` <br> `<Instrument:note>` (class) <br> `<String>` (integer) <br> `<Fret>` (integer) <br> `<Drums:note>` (MIDI value) <br> `<Effect>` (class) <br> `<Wait>` (integer)</details>                                                                                                          | [BPE](https://arxiv.org/abs/2304.08953) [Unigram](https://arxiv.org/abs/2304.08953)                                                                                        | 2140            | Guitar      |


#### Composite tokens

| **Tokenization**                                                                      | **Musical features**                                                                                                                                                                                                                                           | **Embedded object**                             | **Data**                                 |
| ------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------- | ---------------------------------------- |
| [Luo & al. (2020)](http://doi.org/10.1007/978-981-15-2756-2_8) (MG-VAE)               | <details>`<Pitch>` (class) <br> `<Interval>` (number) <br> `<Rhythm>` (class)</details>                                                                                                                                                                        | 3-long vector                                   | Monophonic                               |
| [Zhang (2020)](http://doi.org/10.1109/TNNLS.2020.2990746)                             | <details>`<Program>` (class) <br> `<Pitch>` (integer) <br> `<Velocity>` (integer)</details>                                                                                                                                                                    | 3-long vector + Time-shift                      | Multi-track                              |
| [PiRhDy (2020)](http://doi.org/10.1145/3394171.3414032)                               | <details>`<Chroma>` (class) <br> `<Octave>` (integer) <br> `<Inter-onset-interval>` (music time) <br> `<Note-state>` (class) <br> `<Velocity>` (integer)</details>                                                                                             | 5-long vector                                   | Multi-track                              |
| [Zixun & al. (2021)](http://doi.org/10.1109/IJCNN52387.2021.9533493)                  | <details>`<Pitch>` (one-hot) <br> `<Duration>` (one-hot) <br> `<Current-chord>` (one-hot) <br> `<Next-chord>` (one-hot) <br> `<Bar>` (one-hot)</details>                                                                                                       | 246-long vector                                 | Lead sheet                               |
| [Octuple (2021)](http://doi.org/10.18653/v1/2021.findings-acl.70) (MusicBERT)         | <details>`<Time-signature>` (class) <br> `<Tempo>` (integer) <br> `<Bar>` (integer) <br> `<Position>` (music time) <br> `<Instrument>` (class) <br> `<Pitch>` (MIDI value) <br> `<Duration>` (music time) <br> `<Velocity>` (integer)</details>                | 8-long vector                                   | Multi-track                              |
| [Dong & al. (2023)](http://doi.org/10.1109/ICASSP49357.2023.10094628) (MMT)           | <details>`<Type>` (class) <br> `<Beat>` (integer) <br> `<Position>` (music time) <br> `<Pitch>` (MIDI value) <br> `<Duration>` (music time) <br> `<Instrument>` (class)</details>                                                                              | 6-long vector                                   | Multi-track                              |
| [Dalmazzo & al. (2023)](https://hal.science/hal-04465285) (Chordinator)               | <details>`<Chord-root>` (class) <br> `<Chord-nature>` (class) <br> `<Chord-extensions>` (class) <br> `<MIDI-array>` (multi-hot) <br> `<Slash-chord>` (boolean)</details>                                                                                       | 8-long vector                                   | Chord sequences                          |
| [Wang & al. (2021)](https://archives.ismir.net/ismir2021/paper/000090.pdf) (MuseBERT) | <details>`<Onset>` (music time) <br> `<Pitch>` (MIDI value) <br> `<Duration>` (music time) <br> + factorized properties</details>                                                                                                                              | Matrices of factorized attributes and relations | Multi-track                              |
| [MuMIDI (2020)](http://doi.org/10.1145/3394171.3413721)                               | <details>`<Bar>` <br> `<Position>` (music time) <br> `<Tempo>` (integer) <br> `<Track>` (class) <br> `<Chord>` (class) <br> `<Pitch>` (MIDI value) <br> `<Drum>` (MIDI value) <br> `<Velocity>` (integer) <br> `<Duration>` (music time)</details>             | Note / Event grouping                           | Multi-track                              |
| [Compound Word (2021)](http://doi.org/10.48550/arXiv.2101.02402)                      | <details>`<Family>` (class) <br> `<Time-signature>` (class) <br> `<Bar>` (integer) <br> `<Beat>` (music time) <br> `<Chord>` (class) <br> `<Tempo>` (integer) <br> `<Pitch>` (MIDI value) <br> `<Duration>` (music time) <br> `<Velocity>` (integer)</details> | Note / Event grouping                           | Piano                                    |
| [Di & al. (2021)](http://doi.org/10.1145/3474085.3475195)                             | <details>`<Type>` (class) <br> `<Bar/beat>` (integer) <br> `<Density>` (class) <br> `<Strenth>` (class) <br> `<Instrument>` (integer) <br> `<Pitch>` (MIDI value) <br> `<Duration>` (music time)</details>                                                     | Note / Event grouping                           | Multi-track                              |
| [Makris & al. (2022)](http://doi.org/10.1007/978-3-031-03789-4_12)                    | <details>Encoder input: <br> `<Onset>` (number) <br> `<Group>` (class) <br> `<Type>` (class) <br> `<Duration>` (music time or none) <br> `<Value>` (any - depends on type) <br> Decoder output: <br> `<Onset>` (number) <br> `<Drums>` (integer)</details>     | Note / Event grouping                           | Encoder: Multi-track <br> Decoder: Drums |

## Models

### Recurrent models

#### RNN 

| **Model**                                                     | **Recurrent unit** | **Architecture** | **Data**    | **Representation**      | **Tasks**       |
| ------------------------------------------------------------- | ------------------ | ---------------- | ----------- | ----------------------- | --------------- |
| [RNN-RBM (2012)](https://icml.cc/2012/papers/590.pdf)         | Vanilla RNN        | RBM + RNN        | Multi-track | Time-slice (piano roll) | Free generation |
| [RNN-DBN (2014)](http://doi.org/10.1007/978-3-319-11179-7_28) | Vanilla RNN        | RBM + DBN + RNN  | Multi-track | Time-slice (piano roll) | Free generation |

#### LSTM 

| **Model**                                                                                                                                                                                   | **Recurrent unit** | **Architecture**                         | **Data**        | **Representation**                                          | **Tasks**                                          |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------ | ---------------------------------------- | --------------- | ----------------------------------------------------------- | -------------------------------------------------- |
| [Folk-RNN (2016)](https://arxiv.org/abs/1604.08723) <br> [*Code*](https://github.com/IraKorshunova/folk-rnn)                                                                                | LSTM               | LSTM                                     | Monophonic      | ABC notation                                                | Free generation                                    |
| [C-RNN-GAN (2016)](https://mogren.one/publications/2016/c-rnn-gan/) <br> [*Code*](https://github.com/olofmogren/c-rnn-gan)                                                                  | LSTM               | GAN + Bi-LSTM                            | Multi-track     | Pitch + duration + time-shift + velocity (composite tokens) | Free generation                                    |
| [Song from Pi (2016)](https://arxiv.org/abs/1611.03477)                                                                                                                                     | LSTM               | Hierarchical + LSTM                      | Multi-track     | Custom features (composite tokens)                          | Free generation (melody, chord, drum generation)   |
| [Melody / Attention-RNN (2016)](https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn) <br> [*Code*](https://github.com/magenta/magenta/tree/main/magenta/models/melody_rnn) | LSTM               | LSTM (+ Attention)                       | Monophonic      | Note-ON / Note-OFF                                          | Priming                                            |
| [DeepBach (2017)](http://proceedings.mlr.press/v70/hadjeres17a/hadjeres17a.pdf) <br> [*Code*](https://github.com/Ghadjeres/DeepBach)                                                        | LSTM               | Bi-LSTM                                  | 4-part chorales | Time-slice-based                                            | Harmonization <br> Free generation                 |
| [Anticipation-RNN (2017)](https://arxiv.org/abs/1709.06404) <br> [*Code*](https://github.com/Ghadjeres/Anticipation-RNN)                                                                    | LSTM               | LSTM                                     | Monophonic      | Pitch + duration (time-slice-based)                         | Infilling                                          |
| [JamBot (2017)](http://doi.org/10.1109/ICTAI.2017.00085) <br> [*Code*](https://github.com/brunnergino/JamBot)                                                                               | LSTM               | LSTM                                     | Multi-track     | Time-slice (piano roll)                                     | Chord generation <br> Chord-conditioned generation |
| [Note-RNN / RL Tuner (2017)](https://openreview.net/forum?id=Syyv2e-Kx) <br> [*Code*](https://github.com/magenta/magenta/tree/main/magenta/models/rl_tuner)                                 | LSTM               | LSTM (+ Reinforcement Learning)          | Monophonic      | Note-ON / Note-OFF                                          | Free generation                                    |
| [PerformanceRNN (2018)](http://doi.org/10.1007/s00521-018-3758-9) <br> [*Code*](https://github.com/magenta/magenta/tree/main/magenta/models/performance_rnn)                                | LSTM               | LSTM                                     | Piano           | MIDI-like                                                   | Expressive performance generation                  |
| [Chen & al. (2018)](http://doi.org/10.5281/zenodo.1492351) <br> [*Code*](https://github.com/Tsung-Ping/functional-harmony)                                                                  | LSTM               | Bi-LSTM                                  | Piano           | Time-slice (piano roll)                                     | Roman Numeral Analysis                             |
| [StructureNet (2018)](http://doi.org/10.5281/zenodo.1492518)                                                                                                                                | LSTM               | LSTM                                     | Monophonic      | Custom features (composite tokens)                          | Free generation                                    |
| [Music-VAE (2018)](https://proceedings.mlr.press/v80/roberts18a.html) <br> [*Code*](https://github.com/magenta/magenta/tree/main/magenta/models/music_vae)                                  | LSTM               | VAE + LSTM                               | Monophonic      | MIDI-like                                                   | Samples interpolation <br> Free generation         |
| [JazzGAN (2018)](https://musicalmetacreation.org/mume2018/proceedings/Trieu.pdf)                                                                                                            | LSTM               | GAN + LSTM                               | Lead sheet      | Pitch + duration + chord (event-based)                      | Chord-conditioned generation                       |
| [DeepJ (2018)](http://doi.org/10.1109/ICSC.2018.00077) <br> [*Code*](https://github.com/calclavia/DeepJ)                                                                                    | LSTM               | Biaxial LSTM                             | Piano           | Time-slice (piano roll)                                     | Free generation <br> Style embedding analysis      |
| [Chen & al. (2019)](http://doi.org/10.1109/MMRP.2019.00022)                                                                                                                                 | LSTM               | Bi-LSTM                                  | Lead sheet      | Time-slice (piano roll)                                     | Chord-conditioned generation                       |
| [Makris & al. (2019)](http://doi.org/10.1007/s00521-018-3708-6)                                                                                                                             | LSTM               | LSTM (Drums) / Feed-forward (Context)    | Multi-track     | Drums: event-based <br> Context: time-slice                 | Drums accompaniment generation                     |
| [MahlerNet (2019)](http://doi.org/10.5281/zenodo.3755967) <br> [*Code*](https://github.com/fast-reflexes/MahlerNet)                                                                         | LSTM               | VAE + Bi-LSTM                            | Multi-track     | Event-based                                                 | Samples interpolation                              |
| [GrooVAE (2019)](https://arxiv.org/abs/1905.06118) <br> [*Code*](https://github.com/magenta/magenta/tree/main/magenta/models/music_vae)                                                     | LSTM               | VAE + Bi-LSTM                            | Drums           | Time-slice (drumroll)                                       | Drum Infilling <br> Tap2Drum <br> Humanization     |
| [Wu & al. (2019)](http://doi.org/10.1109/TCYB.2019.2953194)                                                                                                                                 | LSTM               | Hierarchical + Bi-LSTM                   | Monophonic      | Note-ON / Note-OFF                                          | Structure-conditioned generation                   |
| [VirtuosoNet (2019)](http://doi.org/10.5281/zenodo.3527962) <br> [*Code*](https://github.com/jdasam/virtuosoNet)                                                                            | LSTM               | Hierarchical + VAE + Bi-LSTM + Attention | Piano           | Custom features (composite tokens)                          | Expressive performance generation                  |
| [Amadeus (2019)](https://arxiv.org/abs/1902.01973)                                                                                                                                          | LSTM               | Hierarchical + Reinforcement Learning    | Piano           | Pitch + duration (event-based)                              | Free generation                                    |
| [MuseAE (2020)](https://arxiv.org/abs/2001.05494) <br> [*Code*](https://github.com/Andrea-V/MusAE)                                                                                          | LSTM               | Adversarial Auto-encoder + LSTM          | Multi-track     | Time-slice (piano roll)                                     | Samples interpolation <br> Embedding analysis      |
| [Jin & al. (2020)](http://doi.org/10.1007/s11063-020-10241-8)                                                                                                                               | LSTM               | LSTM + Reinforcement Learning            | Multi-track     | Time-slice (piano roll)                                     | Free generation                                    |
| [GGA-MG (2020)](https://arxiv.org/abs/2004.04687) <br> [*Code*](https://github.com/asigalov61/Amazon-Deep-Composer)                                                                         | LSTM               | Bi-LSTM + Genetic Algorithm              | Monophonic      | ABC notation                                                | Free generation                                    |
| [Yu & al. (2021)](http://doi.org/10.1145/3424116) <br> [*Code*](https://github.com/yy1lab/Lyrics-Conditioned-Neural-Melody-Generation)                                                      | LSTM               | GAN + LSTM                               | Monophonic      | Pitch + duration (event-based)                              | Lyrics-conditioned generation                      |
| [CM-HRNN (2021)](http://doi.org/10.1109/IJCNN52387.2021.9533493) <br> [*Code*](https://github.com/guozixunnicolas/CM-HRNN)                                                                  | LSTM               | Hierarchical + LSTM                      | Lead sheet      | Pitch + duration + chord + bar (composite tokens)           | Chord-conditioned generation                       |
| [Keerti & al. (2022)](http://doi.org/10.1007/s11042-021-11881-1)                                                                                                                            | LSTM               | Bi-LSTM + Attention                      | Monophonic      | Pitch + duration (event-based)                              | Sequence reconstruction                            |
| [LStoM (2022)](http://doi.org/10.5281/zenodo.7316773) <br> [*Code*](https://github.com/bytedance/midi_melody_extraction)                                                                    | LSTM               | Bi-LSTM                                  | Multi-track     | Custom features (event-based)                               | Melody extraction                                  |
| [Turker & al. (2022)](http://doi.org/10.1145/3527927.3532790)                                                                                                                               | LSTM               | VAE + LSTM                               | Piano           | Note-ON / Note-OFF                                          | Sequence reconstruction <br> Latent space analysis |

#### GRU

| **Model**                                                                                                                       | **Recurrent unit** | **Architecture**         | **Data**            | **Representation**                            | **Tasks**                                                               |
| ------------------------------------------------------------------------------------------------------------------------------- | ------------------ | ------------------------ | ------------------- | --------------------------------------------- | ----------------------------------------------------------------------- |
| [MIDI-VAE (2018)](https://archives.ismir.net/ismir2018/paper/000204.pdf) <br> [*Code*](https://github.com/brunnergino/MIDI-VAE) | GRU                | VAE + GRU                | Multi-track         | Time-slice (piano roll)                       | Style transfer <br> Samples interpolation                               |
| [XiaoIce Band (2018)](http://doi.org/10.1145/3219819.3220105)                                                                   | GRU                | GRU + Attention          | Multi-track         | Pitch + duration + chord (event-based)        | Chord-conditioned generation <br> Arrangement generation                |
| [Songwriter (2019)](http://doi.org/10.1007/978-3-030-32233-5_39)                                                                | GRU                | GRU + Attention          | Monophonic          | Pitch + duration (event-based)                | Lyrics-conditioned generation                                           |
| [Yang & al. (2019)](https://arxiv.org/abs/1906.03626) <br> [*Code*](https://github.com/buggyyang/Deep-Music-Analogy-Demos)      | GRU                | VAE + bi-GRU             | Lead sheet          | Time-slice (piano roll) + chords (chromagram) | Melody contour-conditioned generation <br> Chord-conditioned generation |
| [BUTTER (2020)](https://aclanthology.org/2020.nlp4musa-1.11) <br> [*Code*](https://github.com/ldzhangyx/BUTTER)                 | GRU                | VAE + GRU                | Monophonic          | Time-slice (piano roll)                       | Text-based query <br> Music captioning <br> Text-conditioned generation |
| [Kong & al. (2020)](https://arxiv.org/abs/2010.14805) <br> [*Code*](https://github.com/bytedance/GiantMIDI-Piano)               | GRU                | Bi-GRU                   | Piano               | Time-slice (piano roll)                       | Composer classification                                                 |
| [MG-VAE (2020)](http://doi.org/10.1007/978-981-15-2756-2_8)                                                                     | GRU                | VAE + Bi-GRU             | Monophonic          | Pitch + interval + duration (event-based)     | Free generation                                                         |
| [PianoTree-VAE (2020)](http://doi.org/10.5281/zenodo.4245446) <br> [*Code*](https://github.com/ZZWaang/PianoTree-VAE)           | GRU                | VAE + bi-GRU             | Piano / Multi-track | Time-slice (pianoroll / MIDI-like)            | Samples interpolation <br> Free generation <br> Embedding analysis      |
| [Su & al. (2022)](http://doi.org/10.1109/CISCE55963.2022.9851120)                                                               | GRU                | Bi-GRU + CNN + Attention | Monophonic          | Pitch + duration (time-slice-based)           | Free generation                                                         |

### Attention-based models

#### End-to-end models

##### Transformer decoder-only architecture

| **Model**                                                                                                                                                 | **Base model**                            | **MIR mechanism**                               | **Data**                  | **Representation**                    | **Tasks**                                                           |
| --------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ----------------------------------------------- | ------------------------- | ------------------------------------- | ------------------------------------------------------------------- |
| [Music Transformer (2018)](https://openreview.net/forum?id=rJe4ShAcF7) <br> [*Code*](https://github.com/jason9693/musictransformer-tensorflow2.0)         | Transformer decoder                       | Relative attention                              | Piano / Choral            | MIDI-like                             | Priming <br> Harmonization                                          |
| [Chen & al. (2020)](https://archives.ismir.net/ismir2020/paper/000349.pdf)                                                                                | Transformer-XL                            | -                                               | Guitar tabs               | REMI-derived (tabs)                   | Free tabs generation                                                |
| [Pop Music Transformer (2020)](http://doi.org/10.1145/3394171.3413671) <br> [*Code*](https://github.com/YatingMusic/remi)                                 | Transformer-XL                            | -                                               | Piano                     | REMI                                  | Priming <br> Free generation                                        |
| [Jazz Transformer (2020)](https://archives.ismir.net/ismir2020/paper/000339.pdf) <br> [*Code*](https://github.com/slSeanWU/jazz_transformer)              | Transformer-XL                            | -                                               | Lead sheet                | REMI-derived (chords)                 | Free generation                                                     |
| [PopMAG (2020)](http://doi.org/10.1145/3394171.3413721)                                                                                                   | Transformer-XL                            | -                                               | Multi-track               | MuMIDI                                | Accompaniment generation                                            |
| [Wu & al. (2020)](https://arxiv.org/abs/2007.07244)                                                                                                       | Transformer-XL                            | -                                               | Piano                     | MIDI-like-derived (composite tokens)  | Free generation                                                     |
| [Di & al. (2020)](http://doi.org/10.1145/3474085.3475195) <br> [*Code*](https://github.com/wzk1015/video-bgm-generation)                                  | Transformer decoder                       | -                                               | Multi-track               | Compound-word-derived (rhythm family) | Video-to-music                                                      |
| [Chang & al. (2021)](https://archives.ismir.net/ismir2021/paper/000011.pdf) <br> [*Code*](https://github.com/reichang182/variable-length-piano-infilling) | XLNet                                     | Relative bar encoding                           | Piano                     | Compound Word                         | Infilling                                                           |
| [Compound Word Transformer (2021)](http://doi.org/10.48550/arXiv.2101.02402) <br> [*Code*](https://github.com/YatingMusic/compound-word-transformer)      | Linear Transformer decoder                | -                                               | Piano                     | Compound Word                         | Priming <br> Free generation                                        |
| [Sarmento & al. (2021)](https://archives.ismir.net/ismir2021/paper/000076.pdf) <br> [*Code*](https://github.com/dada-bots/dadaGP)                         | Transformer-XL                            | -                                               | Guitar tabs + multi-track | DadaGP                                | Metadata-conditioned generation                                     |
| [Sulun & al. (2022)](http://doi.org/10.1109/ACCESS.2022.3169744) <br> [*Code*](https://github.com/serkansulun/midi-emotion)                               | Music Transformer                         | -                                               | Multi-track               | MIDI-like                             | Emotion-conditioned generation                                      |
| [ComMU (2022)](https://openreview.net/pdf?id=Jq3uTzLg9se) <br> [*Code*](https://github.com/POZAlabs/ComMU-code)                                           | Transformer-XL                            | -                                               | Multi-track               | REMI + metadata                       | Metadata-conditioned generation <br> Multi-track combination        |
| [SymphonyNet (2022)](https://archives.ismir.net/ismir2022/paper/000066.pdf) <br> [*Code*](https://github.com/symphonynet/SymphonyNet)                     | Linear Transformer                        | 3-D positional encoding                         | Orchestral                | MMR                                   | Chord-conditioned generation <br> Priming <br> Free generation      |
| [Li & al. (2023)](http://doi.org/10.5281/zenodo.10110056)                                                                                                 | Transformer-XL                            | -                                               | Lead sheet                | REMI-derived (pitch class)            | Free generation                                                     |
| [Multitrack Music Transformer (2023)](http://doi.org/10.1109/ICASSP49357.2023.10094628) <br> [*Code*](https://github.com/salu133445/mmt)                  | Transformer decoder                       | -                                               | Orchestral                | MMT                                   | Free generation <br> Instrument-conditioned generation <br> Priming |
| [GTR-CTRL (2023)](http://doi.org/10.1109/ICASSP49357.2023.10094628)                                                                                       | Transformer-XL                            | -                                               | Guitar tabs + multi-track | DadaGP                                | Instrument-conditioned generation <br> Genre-conditioned generation |
| [ShredGP (2023)](http://doi.org/10.5281/zenodo.10110154)                                                                                                  | Transformer-XL                            | -                                               | Guitar tabs               | DadaGP                                | Style-conditioned generation                                        |
| [Choir Transformer (2023)](https://arxiv.org/abs/2308.02531) <br> [*Code*](https://github.com/Zjy0401/choir-transformer)                                  | Transformer decoder                       | Relative attention                              | 4-part chorales           | Chord + pitch (event-based)           | Harmonization                                                       |
| [Guo & al. (2023)](http://doi.org/10.1609/aaai.v37i4.25635) <br> [*Code*](https://github.com/guozixunnicolas/fundamentalmusicembedding)                   | Transformer decoder with custom attention | Fundamental music embedding <br> RIPO attention | Monophonic                | FME                                   | Priming                                                             |
| [Compose & Embellish (2023)](http://doi.org/10.1109/ICASSP49357.2023.10095098) <br> [*Code*](https://github.com/slSeanWU/Compose_and_Embellish)           | Transformer decoder                       | -                                               | Multi-track               | REMI                                  | Lead sheet priming <br> Accompaniment refinement                    |
| [RHEPP-Transformer (2023)](https://arxiv.org/abs/2306.06040) <br> [*Code*](https://github.com/tangjjbetsy/RHEPP-Transformer)                              | Transformer decoder                       | -                                               | Piano                     | Octuple                               | Expressive performance generation                                   |
| [Angioni & al. (2023)](http://doi.org/10.7717/peerj-cs.1410) <br> [*Code*](https://zenodo.org/records/7786756)                                            | Transformer decoder                       | -                                               | Multi-track               | TSD-like                              | Style classification                                                |
| [Chordinator (2023)](https://hal.science/hal-04465285) <br> [*Code*](https://github.com/Dazzid/theChordinator)                                            | minGPT (no pre-training)                  | -                                               | Chords                    | Custom chord features (+ MIDI array)  | Chord generation                                                    |


##### Transformer encoder-only architecture

| **Model**                                                    | **Base model**         | **MIR mechanism** | **Data**        | **Representation**                | **Tasks**           |
| ------------------------------------------------------------ | ---------------------- | ----------------- | --------------- | --------------------------------- | ------------------- |
| [MTBert (2023)](http://doi.org/10.1007/978-3-031-36805-9_25) | BERT (no-pre-training) | -                 | 4-part chorales | Interval + duration (event-based) | Fugue form analysis |

##### Transformer encoder-decoder architecture

| **Model**                                                                                                                               | **Base model**                                      | **MIR mechanism**                                 | **Data**    | **Representation**                                        | **Tasks**                                   |
| --------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- | ------------------------------------------------- | ----------- | --------------------------------------------------------- | ------------------------------------------- |
| [Transformer-VAE (2020)](http://doi.org/10.1109/ICASSP40776.2020.9054554)                                                               | Transformer encoder-decoder                         | -                                                 | Monophonic  | Pitch + duration (time-slice-based)                       | Priming                                     |
| [Harmony Transformer (2021)](http://doi.org/10.5334/tismir.65) <br> [*Code*](https://github.com/Tsung-Ping/Harmony-Transformer)         | Transformer encoder-decoder                         | -                                                 | Piano       | Pianoroll time-slices                                     | Roman Numeral Analysis                      |
| [Makris & al. (2021)](http://doi.org/10.1109/IJCNN52387.2021.9533474) <br> [*Code*](https://github.com/melkor169/LeadSheetGen_Valence)  | Transformer encoder-decoder                         | -                                                 | Lead sheet  | Encoder: bar features / Decoder: chord + pitch + duration | Emotion-conditioned generation              |
| [Liutkus & al. (2021)](https://proceedings.mlr.press/v139/liutkus21a.html) <br> [*Code*](https://github.com/aliutkus/spe)               | Performer                                           | Stochastic positional encoding                    | Multi-track | REMI / MIDI-like-derived (multi-track)                    | Free generation <br> Groove continuation    |
| [Gover & al. (2022)](https://archives.ismir.net/ismir2022/paper/000003.pdf)                                                             | BART                                                | -                                                 | Piano       | REMI-derived (hands token)                                | Arrangement generation                      |
| [Museformer (2022)](https://openreview.net/forum?id=GFiqdZOm-Ei) <br> [*Code*](https://github.com/microsoft/muzic/tree/main/museformer) | Transformer encoder-decoder with custom attention   | Fine-/coarse-grained attention <br> Bar selection | Multi-track | REMI                                                      | Free generation                             |
| [Theme Transformer (2022)](http://doi.org/10.1109/TMM.2022.3161851) <br> [*Code*](https://github.com/atosystem/ThemeTransformer)        | Transformer encoder-decoder                         | Theme-aligned positional encoding                 | Multi-track | REMI-derived (theme tokens)                               | Theme-conditioned generation                |
| [FIGARO (2022)](https://arxiv.org/abs/2201.10936) <br> [*Code*](https://github.com/dvruette/figaro)                                     | Transformer encoder-decoder                         | -                                                 | Multi-track | REMI+                                                     | Controllable generation                     |
| [MuseMorphose (2023)](http://doi.org/10.1109/TASLP.2023.3270726) <br> [*Code*](https://github.com/YatingMusic/MuseMorphose)             | Transformer encoder + Transformer-XL                | In-attention conditioning                         | Piano       | REMI-derived (multi-track)                                | Style transfer <br> Controllable generation |
| [Accomontage 3 (2023)](https://arxiv.org/abs/2310.16334) <br> [*Code*](https://github.com/zhaojw1998/AccoMontage-3)                     | Transformer encoder-decoder                         | Instrument embedding                              | Multi-track | Piano roll time-slices                                    | Accompaniment generation                    |
| [TeleMelody (2023)](https://arxiv.org/abs/2109.09617) <br> [*Code*](https://github.com/microsoft/muzic/tree/main/telemelody)            | Transformer encoder-decoder                         | -                                                 | Monophonic  | Bar + position + pitch + duration (event-based)           | Lyrics-to-melody                            |
| [MuseCoco (2023)](http://doi.org/10.48550/arXiv.2306.00110) <br> [*Code*](https://github.com/microsoft/muzic/tree/main/musecoco)        | Text2Attr: BERT <br> Attr2Music: Linear Transformer | -                                                 | Multi-track | REMI                                                      | Text-to-MIDI                                |

##### Model combinations

| **Model**                                                                                                                          | **Base model**                                                                                          | **MIR mechanism**    | **Data**    | **Representation**                        | **Tasks**                                                          |
| ---------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | -------------------- | ----------- | ----------------------------------------- | ------------------------------------------------------------------ |
| [Zhang (2020)](http://doi.org/10.1109/TNNLS.2020.2990746)                                                                          | Generator: Transformer decoder <br>Discriminator: Transformer encoder                                   | -                    | Multi-track | MIDI-like-derived (composite tokens)      | Free generation                                                    |
| [Transformer-GAN (2021)](http://doi.org/10.1609/aaai.v35i1.16117) <br> [*Code*](https://github.com/amazon-science/transformer-gan) | Generator: Transformer-XL <br>Discriminator: BERT                                                       | -                    | Piano       | MIDI-like                                 | Free generation                                                    |
| [Dai & al. (2021)](https://archives.ismir.net/ismir2021/paper/000017.pdf)                                                          | Generator: Transformer encoder <br> Discriminator: LSTM                                                 | -                    | Multi-track | Pitch + rhythm (event-based)              | Structure-conditioned generation <br> Chord conditioned generation |
| [Choi & al. (2021)](http://doi.org/10.1109/ACCESS.2021.3065831) <br> [*Code*](https://github.com/ckycky3/CMT-pytorch)              | Chord encoder: Bi-LSTM <br> Rhythm decoder: Transformer decoder <br> Pitch decoder: Transformer decoder | -                    | Lead sheet  | Pitch + rhythm + chord (time-slice-based) | Chord-conditioned generation                                       |
| [Makris & al. (2022)](http://doi.org/10.1007/978-3-031-03789-4_12) <br> [*Code*](https://github.com/melkor169/CP_Drums_Generation) | Bi-LSTM encoder / Transformer encoder                                                                   | -                    | Multi-track | Compound-word-derived                     | Drums accompaniment generation                                     |
| [Neves & al. (2022)](http://doi.org/10.5281/zenodo.7316763) <br> [*Code*](https://github.com/pneves1051/transformers_sentiment)    | Generator: Linear Transformer <br> Discriminator: Linear Transformer                                    | Local prediction map | Piano       | REMI                                      | Emotion-conditioned generation                                     |
| [Q&A (2023)](https://www.ijcai.org/proceedings/2023/0652.pdf) <br> [*Code*](https://github.com/zhaojw1998/Query-and-reArrange)     | PianoTree-VAE <br> Transformer decoder                                                                  | Instrument embedding | Multi-track | Piano roll time-slices                    | Accompaniment generation                                           |
| [Duan & al. (2023)](http://doi.org/10.1145/3572031)                                                                                | Generator: Transformer encoder <br> Discriminator: LSTM                                                 | -                    | Monophonic  | Pitch + duration + rest (event-based)     | Lyrics-to-melody                                                   |
| [Video2Music (2023)](https://arxiv.org/abs/2311.00968) <br> [*Code*](https://github.com/AMAAI-Lab/Video2Music)                     | GRU + Transformer encoder-decoder                                                                       | -                    | Multi-track | MIDI-like                                 | Video-to-music                                                     |




#### Pre-trained models

##### Transformer encoder-only architecture

| **Model**                                                                                                                                 | **Base model**                                     | **MIR mechanism**                                                 | **Data**    | **Representation**                           | **Tasks**                                                                                           |
| ----------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------- | ----------------------------------------------------------------- | ----------- | -------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| [MuseBERT (2021)](https://archives.ismir.net/ismir2021/paper/000090.pdf) <br> [*Code*](https://github.com/ZZWaang/musebert)               | BERT                                               | Generalized relative positional encoding                          | Multi-track | MuseBERT representation                      | Controllable generation <br> Chord analysis <br> Accompaniment refinement                           |
| [MidiBERT-Piano (2021)](https://arxiv.org/abs/2107.05223) <br> [*Code*](https://github.com/wazenmai/MIDI-BERT/)                           | BERT                                               | -                                                                 | Piano       | REMI / Compound Word                         | Melody extraction <br> Velocity prediction <br> Composer classification <br> Emotion classification |
| [MusicBERT (2021)](http://doi.org/10.18653/v1/2021.findings-acl.70) <br> [*Code*](https://github.com/microsoft/muzic/tree/main/musicbert) | RoBERTa                                            | Bar-level masking                                                 | Multi-track | Octuple                                      | Melody completion <br> Accompaniment suggestion <br> Genre classification <br> Style classification |
| [DBTMPE (2021)](http://doi.org/10.3390/math9050530)                                                                                       | Transformer encoder                                | -                                                                 | Multi-track | Pitch combinations + durations (event-based) | Style classification                                                                                |
| [MRBERT (2023)](http://doi.org/10.3390/math11040798)                                                                                      | BERT                                               | Melody/rhythm cross-attention                                     | Lead sheet  | Pitch + duration (event-based)               | Free generation <br> Infilling <br> Chord analysis                                                  |
| [SoloGPBERT (2023)](http://doi.org/10.5281/zenodo.10110154)                                                                               | BERT                                               | -                                                                 | Guitar tabs | DadaGP                                       | Guitar player classification                                                                        |
| [Shen & al. (2023)](http://doi.org/10.1145/3591106.3592237)                                                                               | MidiBERT-Piano                                     | Pre-training tasks <br> (quad-attribute masking / key prediction) | Multi-track | Compound Word simplified                     | Melody extraction <br> Velocity prediction <br> Composer classification <br> Emotion classification |
| [CLaMP (2023)](https://archives.ismir.net/ismir2023/paper/000017.pdf) <br> [*Code*](https://github.com/microsoft/muzic/tree/main/clamp)   | Text encoder: DislRoBERTa <br> Music encoder: BERT | -                                                                 | Lead sheet  | ABC notation-derived                         | Text-based semantic music search <br> Music recommandation <br> Music classification                |



##### Transformer decoder-only architecture

| **Model**                                                                                                                 | **Base model** | **MIR mechanism**                       | **Data**    | **Representation**        | **Tasks**                                                                 |
| ------------------------------------------------------------------------------------------------------------------------- | -------------- | --------------------------------------- | ----------- | ------------------------- | ------------------------------------------------------------------------- |
| [LakhNES (2019)](http://doi.org/10.5281/zenodo.3527901) <br> [*Code*](https://github.com/chrisdonahue/LakhNES)            | Transformer-XL | -                                       | Multi-track | MIDI-like                 | Free generation                                                           |
| [Musenet (2019)](https://openai.com/research/musenet)                                                                     | GPT-2          | Timing embedding / Structural embedding | Multi-track | MIDI-like                 | Priming                                                                   |
| [MMM (2020)](https://arxiv.org/abs/2008.06048) <br> [*Code*](https://github.com/AI-Guru/MMM-JSB)                          | GPT-2          | -                                       | Multi-track | MultiTrack representation | Free generation <br> Priming <br> Inpainting <br> Controllable generation |
| [Angioni & al. (2023)](http://doi.org/10.7717/peerj-cs.1410) <br> [*Code*](https://zenodo.org/records/7786756)            | GPT-2          | -                                       | Multi-track | TSD-like                  | Priming                                                                   |
| [Zhang & al. (2023)](https://openreview.net/pdf?id=haiht1U7pGL) <br> [*Code*](https://github.com/zharry29/drums-with-llm) | GPT-3          | -                                       | Drums       | Drumroll time-slices      | Priming                                                                   |
| [Bubeck & al. (2023)](https://arxiv.org/abs/2303.12712)                                                                   | GPT-4          | -                                       | Text        | ABC notation              | Text-to-ABC                                                               |


##### Transformer encoder-decoder architecture

| **Model**                                                                                                        | **Base model**                | **MIR mechanism** | **Data**    | **Representation**             | **Tasks**                                                                                           |
| ---------------------------------------------------------------------------------------------------------------- | ----------------------------- | ----------------- | ----------- | ------------------------------ | --------------------------------------------------------------------------------------------------- |
| [MusIAC (2022)](http://doi.org/10.1007/978-3-031-03789-4_22) <br> [*Code*](https://github.com/ruiguo-bio/MusIAC) | Transformer encoder-decoder   | -                 | Multi-track | REMI                           | Infilling <br> Controllable generation                                                              |
| [Li & al. (2023)](http://doi.org/10.3390/math11051111)                                                           | Transformer encoder-decoder   | -                 | Lead sheet  | Pitch + duration (event-based) | Harmony analysis <br> Chord generation                                                              |
| [Fu & al. (2023)](http://doi.org/10.1109/IMCOM56909.2023.10035617)                                               | MusicBERT + Music Transformer | -                 | Multi-track | Octuple                        | Melody completion <br> Accompaniment suggestion <br> Genre classification <br> Style classification |
| [Multi-MMLG (2023)](http://doi.org/10.1007/s00521-023-08924-z)                                                   | XLNet + MuseBERT              | -                 | Multi-track | Compound-word-derived          | Melody extraction                                                                                   |


##### Comparative studies

| **Model**                                                                                                                           | **Base model**                                              | **MIR mechanism** | **Data**   | **Representation** | **Tasks**       |
| ----------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------- | ----------------- | ---------- | ------------------ | --------------- |
| [Ferreira & al. (2023)](http://doi.org/10.3390/app13074543) <br> [*Code*](https://github.com/p-ferreira/generating-music-with-data) | GRU / Performance-RNN / GPT-2 / Music Transformer / MuseNet | -                 | Piano      | MIDI-like          | Free generation |
| [Wu & al. (2023)](https://openreview.net/forum?id=QmWXskBhesn) <br> [*Code*](https://github.com/sander-wood/text-to-music)          | BERT / GPT-2 / BART                                         | -                 | Lead sheet | ABC notation       | Text-to-ABC     |




## Citation
If you find this useful, please cite our paper.

```
bibtex
```
